{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unsupervised_Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "-NSHwJwWgd1Q",
        "outputId": "476080d9-2d15-4c92-8613-730b8afb4168"
      },
      "source": [
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-90592a3d-4335-4189-97d9-ed531438fc4a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-90592a3d-4335-4189-97d9-ed531438fc4a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle (1).json to kaggle (1).json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle (1).json': b'{\"username\":\"muhammad4hmed\",\"key\":\"a317a4fe658a1328ab0a5549b9296b17\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDPWO6CWgoib",
        "outputId": "cc489514-1572-4f26-f747-f637f1627fbe"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZJnBlS7gyBJ"
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Rvu74HOgRYy",
        "outputId": "e86c59c2-1e20-4ae5-be66-64bdcdfe96f3"
      },
      "source": [
        "!kaggle datasets download -d musha2017/shopee-external-models"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading shopee-external-models.zip to /content\n",
            "100% 1.26G/1.26G [00:19<00:00, 69.0MB/s]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw8nUBSJg8Xj",
        "outputId": "36c63de2-3bf3-4016-d958-44e62d5ed364"
      },
      "source": [
        "!unzip /content/shopee-external-models.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/shopee-external-models.zip\n",
            "  inflating: EfficientNetB3_M0.7_512_42.h5  \n",
            "  inflating: Keras_Applications-1.0.8-py3-none-any.whl  \n",
            "  inflating: bert_en_uncased_L-24_H-1024_A-16_1/assets/vocab.txt  \n",
            "  inflating: bert_en_uncased_L-24_H-1024_A-16_1/saved_model.pb  \n",
            "  inflating: bert_en_uncased_L-24_H-1024_A-16_1/variables/variables.data-00000-of-00001  \n",
            "  inflating: bert_en_uncased_L-24_H-1024_A-16_1/variables/variables.index  \n",
            "  inflating: efficientnet-1.1.0-py3-none-any.whl  \n",
            "  inflating: tokenization.py         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty-nt15sawsF",
        "outputId": "a6163e2a-8c23-4a07-8e31-0b4380dd54ba"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\r\u001b[K     |▎                               | 10kB 23.1MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 27.4MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 20.6MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 17.3MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 15.2MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61kB 14.4MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 13.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81kB 13.6MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 13.3MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102kB 13.6MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 13.6MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122kB 13.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133kB 13.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143kB 13.6MB/s eta 0:00:01\r\u001b[K     |████                            | 153kB 13.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 163kB 13.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 204kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 225kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 235kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 256kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 266kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 276kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 296kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 307kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 327kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 348kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 368kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 389kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 399kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 409kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 419kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 440kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 450kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 460kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 471kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 481kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 501kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 512kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 522kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 532kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 542kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 552kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 563kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 573kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 583kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 593kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 614kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 624kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 634kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 645kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 655kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 665kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 675kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 686kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 696kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 706kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 727kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 737kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 747kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 757kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 768kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 778kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 788kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 798kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 808kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 819kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 829kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 839kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 849kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 860kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 870kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 880kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 890kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 901kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 911kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 921kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 931kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 942kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 952kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 962kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 972kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 983kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 993kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0MB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0MB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0MB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.0MB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1MB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1MB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1MB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1MB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1MB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1MB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.1MB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.1MB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2MB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2MB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2MB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2MB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 13.6MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_GZGPoeTZQh",
        "outputId": "0991ddc3-10fb-440f-81b8-8a339d4c6c66"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI84B2vWVEYP"
      },
      "source": [
        "In this notebook, we are going to train a model to extract word embeddings so that we can use them in future and we can have more better context for words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou8yhq4BThvQ"
      },
      "source": [
        "from shutil import copyfile\n",
        "import re\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import backend as K\n",
        "copyfile(src = \"/content/tokenization.py\", dst = \"okenization.py\")\n",
        "import tokenization\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDWMo8LXVgKp"
      },
      "source": [
        "# Configuration\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 32\n",
        "# Seed\n",
        "SEED = 123\n",
        "# Verbosity\n",
        "VERBOSE = 1\n",
        "LR = 0.00001"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koAlktX0Vyk9"
      },
      "source": [
        "# Function to seed everything\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    \n",
        "def read_and_preprocess():\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Clean_Dataset.csv')\n",
        "    # tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n",
        "    # df['matches'] = df['label_group'].map(tmp)\n",
        "    # df['matches'] = df['matches'].apply(lambda x: ' '.join(x))\n",
        "    encoder = LabelEncoder()\n",
        "    df['up_votes'] = encoder.fit_transform(df['up_votes'])\n",
        "    N_CLASSES = df['up_votes'].nunique()\n",
        "    print(f'We have {N_CLASSES} classes')\n",
        "    x_train, x_val, y_train, y_val = train_test_split(df[['title']], df['up_votes'], shuffle = True, random_state = SEED, test_size = 0.33)\n",
        "    return df, N_CLASSES, x_train, x_val, y_train, y_val\n",
        "\n",
        "# Return tokens, masks and segments from a text array or series\n",
        "def bert_encode(texts, tokenizer, max_len=512):\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)\n",
        "            \n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len - len(input_sequence)\n",
        "        \n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
        "        tokens += [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "    \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)\n",
        "\n",
        "\n",
        "# Arcmarginproduct class keras layer\n",
        "class ArcMarginProduct(tf.keras.layers.Layer):\n",
        "    '''\n",
        "    Implements large margin arc distance.\n",
        "\n",
        "    Reference:\n",
        "        https://arxiv.org/pdf/1801.07698.pdf\n",
        "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
        "            blob/master/src/modeling/metric_learning.py\n",
        "    '''\n",
        "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
        "                 ls_eps=0.0, **kwargs):\n",
        "\n",
        "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "        self.ls_eps = ls_eps\n",
        "        self.easy_margin = easy_margin\n",
        "        self.cos_m = tf.math.cos(m)\n",
        "        self.sin_m = tf.math.sin(m)\n",
        "        self.th = tf.math.cos(math.pi - m)\n",
        "        self.mm = tf.math.sin(math.pi - m) * m\n",
        "\n",
        "    def get_config(self):\n",
        "\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'n_classes': self.n_classes,\n",
        "            's': self.s,\n",
        "            'm': self.m,\n",
        "            'ls_eps': self.ls_eps,\n",
        "            'easy_margin': self.easy_margin,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(ArcMarginProduct, self).build(input_shape[0])\n",
        "\n",
        "        self.W = self.add_weight(\n",
        "            name='W',\n",
        "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
        "            initializer='glorot_uniform',\n",
        "            dtype='float32',\n",
        "            trainable=True,\n",
        "            regularizer=None)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        X, y = inputs\n",
        "        y = tf.cast(y, dtype=tf.int32)\n",
        "        cosine = tf.matmul(\n",
        "            tf.math.l2_normalize(X, axis=1),\n",
        "            tf.math.l2_normalize(self.W, axis=0)\n",
        "        )\n",
        "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
        "        phi = cosine * self.cos_m - sine * self.sin_m\n",
        "        if self.easy_margin:\n",
        "            phi = tf.where(cosine > 0, phi, cosine)\n",
        "        else:\n",
        "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
        "        one_hot = tf.cast(\n",
        "            tf.one_hot(y, depth=self.n_classes),\n",
        "            dtype=cosine.dtype\n",
        "        )\n",
        "        if self.ls_eps > 0:\n",
        "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
        "\n",
        "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
        "        output *= self.s\n",
        "        return output\n",
        "\n",
        "# Function to build bert model\n",
        "def build_bert_model(bert_layer, max_len = 512):\n",
        "    \n",
        "    margin = ArcMarginProduct(\n",
        "            n_classes = N_CLASSES, \n",
        "            s = 30, \n",
        "            m = 0.5, \n",
        "            name='head/arc_margin', \n",
        "            dtype='float32'\n",
        "            )\n",
        "    \n",
        "    input_word_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    input_mask = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
        "    segment_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
        "    label = tf.keras.layers.Input(shape = (), name = 'label')\n",
        "\n",
        "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "    clf_output = sequence_output[:, 0, :]\n",
        "    x = margin([clf_output, label])\n",
        "    output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
        "    model = tf.keras.models.Model(inputs = [input_word_ids, input_mask, segment_ids, label], outputs = [output])\n",
        "    model.compile(optimizer = tf.keras.optimizers.Adam(lr = LR),\n",
        "                  loss = [tf.keras.losses.SparseCategoricalCrossentropy()],\n",
        "                  metrics = [tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "    return model\n",
        "\n",
        "def load_train_and_evaluate(x_train, x_val, y_train, y_val):\n",
        "    seed_everything(SEED)\n",
        "    # Load BERT from the Tensorflow Hub\n",
        "    module_url = \"/content/bert_en_uncased_L-24_H-1024_A-16_1\"\n",
        "    bert_layer = hub.KerasLayer(module_url, trainable = True)\n",
        "    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "    do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "    tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
        "    x_train = bert_encode(x_train['title'].values, tokenizer, max_len = 12)\n",
        "    x_val = bert_encode(x_val['title'].values, tokenizer, max_len = 12)\n",
        "    y_train = y_train.values\n",
        "    y_val = y_val.values\n",
        "    # Add targets to train and val\n",
        "    x_train = (x_train[0], x_train[1], x_train[2], y_train)\n",
        "    x_val = (x_val[0], x_val[1], x_val[2], y_val)\n",
        "    bert_model = build_bert_model(bert_layer, max_len = 12)\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(f'Bert_{SEED}.h5', \n",
        "                                                    monitor = 'val_loss', \n",
        "                                                    verbose = VERBOSE, \n",
        "                                                    save_best_only = True,\n",
        "                                                    save_weights_only = True, \n",
        "                                                    mode = 'min')\n",
        "    history = bert_model.fit(x_train, y_train,\n",
        "                             validation_data = (x_val, y_val),\n",
        "                             epochs = EPOCHS, \n",
        "                             callbacks = [checkpoint],\n",
        "                             batch_size = BATCH_SIZE,\n",
        "                             verbose = VERBOSE)\n",
        "    "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQ0gT_PRWE94",
        "outputId": "ad049555-a2d0-4501-d5c2-51c86196ded2"
      },
      "source": [
        "df, N_CLASSES, x_train, x_val, y_train, y_val = read_and_preprocess()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We have 5782 classes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLAJEfXUixLA"
      },
      "source": [
        "x_train['title'].fillna('NA',inplace=True)\n",
        "x_val['title'].fillna('NA',inplace=True)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Br8FQCuEWs_s",
        "outputId": "c8e955f8-5c16-49c8-fa14-5ad8f17c9720"
      },
      "source": [
        "load_train_and_evaluate(x_train, x_val, y_train, y_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10663/10663 [==============================] - 2252s 209ms/step - loss: 18.4557 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 16.6567 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 16.65665, saving model to Bert_123.h5\n",
            "Epoch 2/10\n",
            "10663/10663 [==============================] - 2217s 208ms/step - loss: 15.0240 - sparse_categorical_accuracy: 6.4703e-04 - val_loss: 10.5151 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00002: val_loss improved from 16.65665 to 10.51507, saving model to Bert_123.h5\n",
            "Epoch 3/10\n",
            "10663/10663 [==============================] - 2215s 208ms/step - loss: 10.4172 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 10.6193 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 10.51507\n",
            "Epoch 4/10\n",
            "10663/10663 [==============================] - 2215s 208ms/step - loss: 10.4353 - sparse_categorical_accuracy: 1.0010e-04 - val_loss: 10.4761 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00004: val_loss improved from 10.51507 to 10.47606, saving model to Bert_123.h5\n",
            "Epoch 5/10\n",
            "10663/10663 [==============================] - 2222s 208ms/step - loss: 10.4494 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 10.8338 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 10.47606\n",
            "Epoch 6/10\n",
            "10663/10663 [==============================] - 2231s 209ms/step - loss: 10.4562 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 10.4050 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00006: val_loss improved from 10.47606 to 10.40500, saving model to Bert_123.h5\n",
            "Epoch 7/10\n",
            " 1472/10663 [===>..........................] - ETA: 27:57 - loss: 10.4718 - sparse_categorical_accuracy: 0.0000e+00"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c8XuyGTbE-S"
      },
      "source": [
        "The above trained model can be used to derive the embeddings of sentences"
      ]
    }
  ]
}